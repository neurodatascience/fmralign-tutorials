{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25869859",
   "metadata": {},
   "source": [
    "# Functional alignment\n",
    "\n",
    "We can define functional alignment as transformations which directly align individual functional activity without relying on anatomical landmarks.\n",
    "Specifically, the methods considered here learn these transformations in a high-dimensional functional space,\n",
    "rather than in the three-dimensional space in which we consider anatomically-based transformations.\n",
    "\n",
    "Although this class of methods is broadly referred to as both _functional alignment methods_ and _hyperalignment methods_,\n",
    "we adopt the term _functional alignment methods_ to better distinguish from the specific Procrustes-based hyperalignment method in use in the literature.\n",
    "\n",
    "For these tutorials, we further constrain our definition of functional alignment to only include those methods which learn linear transformations.\n",
    "Other, non-linear methods are in active development, but we focus on linear methods as these broadly retain individual-specific information.\n",
    "\n",
    "## Contrasting anatomically-based alignment\n",
    "\n",
    "With neuroimaging data, we usually make inferences across subjects by creating a mapping between each subject’s neuroanatomy;\n",
    "this is usually done by normalizing their anatomical (T1-weighted) MRI scan to a standard template such as the MNI152.\n",
    "We can then look at similarities across individuals in this standardized space.\n",
    "Although this approach allows us to learnt commonalities across subjects, it can obscure important individual information.\n",
    "\n",
    "A relevant analogy here---originally suggested by [Jack Gallant](https://smartech.gatech.edu/handle/1853/60990)---is to the idea of face averaging.\n",
    "Much like sulci and gyri in MRI data,\n",
    "faces also have relevant landmarks (e.g. eyes) that can be used to generate a mapping between individual's faces.\n",
    "\n",
    "```{figure} ../images/facial_landmarks.png\n",
    "---\n",
    "height: 350px\n",
    "name: facial-landmarks-png\n",
    "---\n",
    "Identifying relevant facial landmarks [using OpenCV](https://learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/).\n",
    "With thanks to [Satya Mallick](https://learnopencv.com/about/).\n",
    "```\n",
    "\n",
    "By using these landmarks, we can identify relevant internal structure within an individual's face; for example, the distance between their eyes.\n",
    "Importantly, because these landmarks are shared across faces, we can generate a mapping between different individual's facial structures.\n",
    "These mappings can then be used to bring one or more faces into alignment, where they can then be averaged, as shown in {numref}`average-president-jpg`\n",
    "\n",
    "```{figure} ../images/average-president.jpg\n",
    "---\n",
    "height: 350px\n",
    "name: average-president-jpg\n",
    "---\n",
    "An average face from six US presidents, generaged [using OpenCV](https://learnopencv.com/average-face-opencv-c-python-tutorial/).\n",
    "With thanks to [Satya Mallick](https://learnopencv.com/about/).\n",
    "\n",
    "```\n",
    "\n",
    "The resulting composite or \"average face\" retains important structure that is consistent across individuals,\n",
    "but this structure is largely defined by the chosen landmarks.\n",
    "This means that idiosyncratic information---particularly information that is not represented in the original landmarks, such as their hairline---is not well-represented in the composite face.\n",
    "\n",
    "## High-dimensional functional spaces\n",
    "\n",
    "Functional alignment doesn't use landmark information to generate its alignments.\n",
    "To understand it, we need to think outside of the box: the box of three dimensions, that is.\n",
    "\n",
    "Usually, we think of fMRI data in a 3D space of _x_, _y_, and _z_ coordinates.\n",
    "This is not the only way to think about our data, however.\n",
    "\n",
    "```{figure} ../images/churchland-1998-fig1.png\n",
    "---\n",
    "height: 375px\n",
    "name: churchland-1998-fig1-png\n",
    "---\n",
    "Three different ways of conceptualizing a given voxelwise activity pattern:\n",
    "a histogram of activation levels, an activation vector, or a point in activation space.\n",
    "Figure adapted from {cite:t}`Churchland1998-lw`.\n",
    "```\n",
    "\n",
    "Instead, we can imagine a new space where our dimensions equal the number of voxels we’re comparing between subjects.\n",
    "To keep things simple, let’s first pretend we are only interested in two voxels.\n",
    "\n",
    "Traditionally, we would extract the activity time courses for these voxels,\n",
    "such that we had two graphs of voxel activity over time.\n",
    "We could then compare the similarity of these time courses using techniques such as correlation.\n",
    "An alternative way to think about these voxel activity profiles is in a new, functional space.\n",
    "That is, we can define a new two-dimensional space,\n",
    "where each dimension corresponds to one voxel's activity.\n",
    "For each time point,\n",
    "we then include a single data point that indexes the relative activity of each voxel at that time point.\n",
    "This basic idea is illustrated in {numref}`voxel-space-gif`.\n",
    "\n",
    "```{figure} ../images/voxel_space.gif\n",
    "---\n",
    "height: 375px\n",
    "name: voxel-space-gif\n",
    "---\n",
    "Moving from anatomical space to a high-dimensional voxel space.\n",
    "Here, we only consider two voxels to aid in visualization.\n",
    "```\n",
    "\n",
    "Note that as we increase the number of voxels, we also increase the number of dimensions.\n",
    "\n",
    "```{margin}\n",
    "Some _latent factor models_ reduce the number of dimensions using an initial decomposition.\n",
    "The idea is that there may be several latent factors supporting voxel-level activity patterns,\n",
    "and we can therefore capture relevant information even in a lower dimensional space.\n",
    "We will cover one such latent factor model, the Shared Response Model, in these tutorials.\n",
    "```\n",
    "\n",
    "Instead of visualizing these spaces, then, we will simply have to reason about them.\n",
    "This takes a bit of getting used to,\n",
    "and it's important to note that [our default intution is often wrong](https://marckhoury.github.io/blog/counterintuitive-properties-of-high-dimensional-space).\n",
    "\n",
    "At a high-level, the goal is to make two distributions of participant activity patterns look as similar as possible,\n",
    "given certain constraints on the transformation.\n",
    "\n",
    "```{figure} ../images/churchland-1998-fig2.png\n",
    "---\n",
    "height: 375px\n",
    "name: churchland-1998-fig2-png\n",
    "---\n",
    "The locations of four protoype points within the voxelwise activation spaces of two brains.\n",
    "Figure adapted from {cite:t}`Churchland1998-lw`.\n",
    "```\n",
    "\n",
    "The precise constraints differ according to the method; however, we are only interested in methods which generate linear mappings.\n",
    "The resulting transformations, then, should improve functional similarity while retaining as much information as possible about individual participants or conditions.\n",
    "\n",
    "The methods used to create these transformations can be considered as part of a broader class of \"distribution alignment\" methods.\n",
    "Although distribution alignment is used in domain adaptation,\n",
    "functional alignment is unique in that we generally have access to both the \"source\" and \"target\" distributions and are trying to learn a relationship between them,\n",
    "rather than transferring a learnt relationship from one distribution to another.\n",
    "\n",
    "The next four tutorials detail different methods for functionally aligning two (or more) high-dimensional, voxel spaces.\n",
    "\n",
    "## Constraining functional alignment to local neighborhoods\n",
    "\n",
    "Since functional alignment is not guided by anatomical landmarks,\n",
    "considering a large number of voxels can generate biologically implausible transformations.\n",
    "For example, we may maximize distribution similarity while aligning voxel activity from one participant's visual cortex to another participant's prefrontal cortex.\n",
    "To avoid this, we can constrain the voxels included in calculating each functional alignment transformation to smaller, local neighborhoods.\n",
    "\n",
    "A relevant neighborhood might be defined by an _a priori_ region of interest (ROI).\n",
    "That is, a researcher may have identified a relevant patch of cortex through functional localizers or anatomical tracing.\n",
    "They can then only consider voxels within this ROI and functionally align their activity across participants.\n",
    "\n",
    "To generate a whole brain transformation, however, we must define many more local neighborhoods.\n",
    "There are two primary strategies to do so.\n",
    "The first is through a deterministic or non-overlapping parcellation.\n",
    "This can be considered as an extension of the ROI-based approach, in that we now have as many ROIs as there are parcels.\n",
    "Transformations are calculated separately for each parcel and then aggregated into a larger whole brain transformation matrix.\n",
    "\n",
    "Alternatively, we can define our local neighborhoods using a searchlight approach.\n",
    "Here, a searchlight is a small sphere of defined radius that we can iterate through a brain volume.\n",
    "Importantly, the centroids of each searchlight are selected such that the spheres slightly overlap.\n",
    "When generating an aggregated transformation, then, this overlap must be accounted for in the transformation itself;\n",
    "for example, by averaging or summing the calculated transformation from two overlapping searchlights.\n",
    "You can see an example of these different local neighborhood methods in {numref}`parcellation-searchlight-png`.\n",
    "\n",
    "```{figure} ../images/parcellation_v_searchlight.png\n",
    "---\n",
    "height: 350px\n",
    "name: parcellation-searchlight-png\n",
    "---\n",
    "Two different methods to constrain functional alignment transformations:\n",
    "non-overlapping parcels from a deterministic parcellation or partially overlapping searchlights.\n",
    "```\n",
    "\n",
    "Importantly, when functional alignment transformations are aggregated using the searchlight methods,\n",
    "the final transformations are no longer guaranteed to have the same properties as the initial, unaggregated transforms.\n",
    "In this work, we therefore assume that functional alignment transformations are calculated in non-overlapping neighborhoods,\n",
    "such as an ROI or a whole brain deterministic parcellation.\n",
    "\n",
    "## Formalizing the problem\n",
    "\n",
    "Suppose we have two data distributions, $X$ and $Y$.\n",
    "These distributions may come from voxel activity time series sampled from two different participants\n",
    "or from the same participant in two different psychological tasks.\n",
    "\n",
    "Each distribution contains a series of $n$ observations, such that\n",
    "$X = \\{\\mathbf{x}_1, \\ldots, \\mathbf{x}_n\\}$\n",
    "where $\\mathbf{x}_i \\in \\mathbb{R}^p$.\n",
    "\n",
    "For fMRI data, then, $n$ would be the number of time points sampled,\n",
    "while $p$ is the number of voxels considered.\n",
    "\n",
    "If we stack all of our data points into two matrices\n",
    "--one for each distribution-- we can represent our two distributions as\n",
    "$\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ and\n",
    "$\\mathbf{Y} \\in \\mathbb{R}^{n \\times p}$.\n",
    "\n",
    "For some methods, we will enforce that every distribution has exactly the same number of voxels $p$.\n",
    "Other methods will allow the number of voxels to vary across distributions.\n",
    "When variable voxels are allowed, we will denote the number of voxels as $p_1$ or $p_2$,\n",
    "corresponding to the relevant distribution.\n",
    "\n",
    "```{bibliography} references.bib\n",
    ":style: unsrt\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst,ipynb",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": "0.9",
    "jupytext_version": "1.5.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "source_map": [
   12
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}