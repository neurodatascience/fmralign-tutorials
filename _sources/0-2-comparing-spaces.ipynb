{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb10ddf",
   "metadata": {},
   "source": [
    "# Distribution alignment\n",
    "\n",
    "With neuroimaging data, we usually make inferences across subjects by creating a mapping between each subjectâ€™s neuroanatomy;\n",
    "this is typically done by normalizing their anatomical (T1-weighted) MRI scan to a standard template such as the MNI152.\n",
    "We can then look at similarities across individuals in this standardized space, assuming that voxel $X_1, Y_1, Z_1$ corresponds across individuals.\n",
    "\n",
    "Assuming we'd like to work with voxelwise data, we would then extract the activity time courses for all given voxels of interest,\n",
    "such that we had graphs of voxel activity over time.\n",
    "We could then compare the similarity of these time courses using techniques such as correlation.\n",
    "To compare across individuals or brain states, then, we would compare summary-level statistics from e.g. network analysis.\n",
    "\n",
    "As shown in {numref}`churchland-1998-fig2-png`,\n",
    "our question then is how best to find correspondence between two (or more) unique functional spaces.\n",
    "\n",
    "```{figure} ../images/churchland-1998-fig2.png\n",
    "---\n",
    "height: 375px\n",
    "name: churchland-1998-fig2-png\n",
    "---\n",
    "The locations of four protoype points within the voxelwise activation spaces of two brains.\n",
    "Figure adapted from {cite:t}`Churchland1998-lw`.\n",
    "```\n",
    "\n",
    "## Formalizing the problem\n",
    "\n",
    "Suppose we have two data distributions, $X$ and $Y$.\n",
    "These distributions may come from voxel activity time series sampled from two different participants\n",
    "or from the same participant in two different psychological tasks.\n",
    "\n",
    "Each distribution contains a series of $n$ observations, such that\n",
    "$X = \\{\\mathbf{x}_1, \\ldots, \\mathbf{x}_n\\}$\n",
    "where $\\mathbf{x}_i \\in \\mathbb{R}^p$.\n",
    "\n",
    "For fMRI data, then, $n$ would be the number of time points sampled,\n",
    "while $p$ is the number of voxels considered.\n",
    "\n",
    "To deal with these equations more easily, we'll need to stack the values of $x$ and $y$ into matrices.\n",
    "Let's define those matrices like this:\n",
    "\n",
    "```{math}\n",
    "Y = \\begin{bmatrix} y(i=1) \\\\\\\\ y(i=2) \\\\\\\\ \\vdots \\\\\\\\ y(i=n) \\end{bmatrix},\n",
    "X = \\begin{bmatrix} x(i=1) \\\\\\\\ x(i=2) \\\\\\\\ \\vdots \\\\\\\\ x(i=n) \\end{bmatrix}\n",
    "```\n",
    "\n",
    "Now we have two matrices, where each matrix represents one of our two distributions\n",
    "$\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ and\n",
    "$\\mathbf{Y} \\in \\mathbb{R}^{n \\times p}$.\n",
    "\n",
    "For some methods, we will enforce that every distribution has exactly the same number of voxels $p$.\n",
    "Other methods will allow the number of voxels to vary across distributions.\n",
    "When variable voxels are allowed, we will denote the number of voxels as $p_1$ or $p_2$,\n",
    "corresponding to the relevant distribution.\n",
    "\n",
    "```{note}\n",
    "Some _latent factor models_ reduce the number of dimensions using an initial decomposition.\n",
    "The idea is that there may be several latent factors supporting voxel-level activity patterns,\n",
    "and we can therefore capture relevant information even in a lower dimensional space.\n",
    "```\n",
    "\n",
    "## References\n",
    "\n",
    "```{bibliography}\n",
    ":style: unsrt\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst,ipynb",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": "0.9",
    "jupytext_version": "1.5.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "source_map": [
   12
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}